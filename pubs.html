<!DOCTYPE html>
<html lang="en-CH">
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-M9KV48G94M"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-M9KV48G94M');
</script>
    <title>Sevda Öğüt | Publications</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" type="image/x-icon" href="images/greenS.png">
    <script src="https://kit.fontawesome.com/cdd5ebfbb8.js" crossorigin="anonymous"></script>
    </head>
<body>

<div class="navitem">
    <a href="index.html"><div>HOME</div></a>
    <a href="pubs.html"><div>PUBLICATIONS</div></a>
    <a href="projects.html"><div>PROJECTS</div></a>
    <a href="fun.html"><div>FUN STUFF</div></a>
</div>

<header>
    <div class="page-info">
        <img src="images/publications.png" alt="Publications"/>
        <h1 id="page-name">Publications</h1>
    </div>
    <div class="line top-line"></div>
    <div class="line bottom-line"></div>
</header>

<div class="timeline-wrapper">
    <div class="timeline-column">
        <svg class="timeline-svg" viewBox="-10 -10 100 1500" preserveAspectRatio="xMidYMin meet">
            <defs>
                <marker id="arrowhead" markerWidth="6" markerHeight="6" 
                refX="3" refY="3" orient="auto-start-reverse"
                markerUnits="strokeWidth">
                <path d="M 0 0 L 6 3 L 0 6 Z" fill="#D4AF37" />
                </marker>
            </defs>
            <path d="M 50 0 L 50 1400" 
            fill="none"
            stroke="#D4AF37"
            stroke-width="2"
            stroke-dasharray="6,6"
            marker-start="url(#arrowhead)" />
            <text x="25" y="0" fill="#D4AF37" font-size="10" font-weight="bold">time</text>
        </svg>
    </div>
    <div class="content-column">

        <div class="marker" style="top: 3vw;">
            <div class="date">arXiv 2025</div>
            <div class="pub-box">
                <strong style="font-size: 1.4em;">
                    GrapHist: Large-Scale Graph Self-Supervised Learning for Histopathology
                </strong>
                <br><br>
                <img src="images/iclr2.png" class="pub-img" style="max-width: 75%;">
                <p> This paper proposes GrapHist, a large-scale graph self-supervised learning framework for histopathology.
                </p>
            </div>
         </div>

        <div class="marker" style="top: 3vw;">
            <div class="date">ICML Workshop Multi-modal Foundation Models and Large Language Models for Life Sciences 2025</div>
            <div class="pub-box">
                <strong style="font-size: 1.4em;">
                    From Vision to Graph Self-Supervised Learning in Digital Pathology
                </strong>
                <br><br>
                <img src="images/icml.png" class="pub-img" style="max-width: 75%;">
                <p> This paper demonstrates that graph-based self-supervision captures spatial structure in digital pathology patches and achieves similar performance to vision-based models using 12x fewer parameters. It also shows late multi-modal fusion of images and graphs improves upon single-modal baselines in digital pathology.
                </p>
                <div class="pub-links">
                    <a href="https://openreview.net/pdf?id=6uTigj0bwJ" class="pub-link">
                        <i class="fa-regular fa-file-lines fa-lg" style="color: #000000;"></i> Paper
                    </a>
                    <div class="separator-line"></div>
                    <a href="https://github.com/LTS4/CarlosHurtado-2025-sem-GraphVsVision" class="pub-link">
                        <i class="fa-solid fa-code fa-lg" style="color: #000000;"></i> Code
                    </a>
                    <div class="separator-line"></div>
                    <a href="citations/citation-icml.html" class="pub-link">
                        <i class="fa-solid fa-quote-right" style="color: #000000;"></i> Cite
                    </a>    
                </div>   
            </div>
         </div>

        <div class="marker" style="top: 3vw;">
            <div class="date">arXiv 2025</div>
            <div class="pub-box">
                <strong style="font-size: 1.4em;">
                    Benchmarking Instance-Level Learnability and Interpretability in Multiple Instance Learning
                </strong>
                <br><br>
                <img src="images/ecml.png" class="pub-img">
                <p>
                    This study presents a unified benchmarking framework that evaluates MIL algorithms at both bag and instance levels, quantifying performance, learnability, and interpretability. Experiments on synthetic and digital pathology datasets reveal that although bag-level performance is robust across aggregation strategies, instance-level metrics are significantly affected by sample size and feature noise.
                </p>
                <div class="pub-links">
                    <a href="https://github.com/ogutsevda/instance-level" class="pub-link">
                        <i class="fa-solid fa-code fa-lg" style="color: #000000;"></i> Code
                    </a>
                </div>
            </div>
        </div>
    
        <div class="marker" style="top: 3vw;">
            <a href="https://sites.google.com/view/icbinb-2025/home?authuser=0">
            <div class="date">ICLR Workshop I Can't Believe It's Not Better 2025</div>
            </a>
            <div class="pub-box">
                <strong style="font-size: 1.4em;">
                    On the Role of Structure in Hierarchical Graph Neural Networks
                </strong>
                <br><br>
                <img src="images/iclr.png" class="pub-img">
                <p>
                    This analysis shows that graph structure is learned in the initial convolutional layers, typically before any pooling schemes are applied, by perturbing the input graph structure at varying depths of the hierarchical graph neural network. In fact, many popular benchmarking datasets for graph-level tasks only exhibit limited structural information relevant to the prediction task, with structure-agnostic baselines often matching or outperforming more complex GNNs. These findings shed light on the empirical underperformance of graph pooling schemes and motivate the need for more structure-sensitive benchmarks and evaluation frameworks.
                </p>
                <div class="pub-links">
                    <a href="https://openreview.net/pdf?id=WpYdiLd5Fm" class="pub-link">
                        <i class="fa-regular fa-file-lines fa-lg" style="color: #000000;"></i> Paper
                    </a>
                    <div class="separator-line"></div>
                    <a href="https://github.com/LTS4/LucaSbicego-2024-sem-ReRethinkingPooling" class="pub-link">
                        <i class="fa-solid fa-code fa-lg" style="color: #000000;"></i> Code
                    </a>
                    <div class="separator-line"></div>
                    <a href="citations/citation-iclr.html" class="pub-link">
                        <i class="fa-solid fa-quote-right" style="color: #000000;"></i> Cite
                    </a>    
                </div>   
            </div>
        </div>
    
        <div class="marker" style="top: 3vw;">
            <a href="https://conferences.sigcomm.org/sigcomm/2023/">
            <div class="date">SIGCOMM 2023</div>
            </a>
            <div class="pub-box">
                <strong style="font-size: 1.4em;">
                    Towards Practical and Scalable Molecular Networks
                </strong>
                <br><br>
                <img src="images/sigcomm.png" class="pub-img" style="max-width: 65%;">
                <p>
                    This work introduces MoMA, a molecular multiple access protocol that enables communication between multiple transmitters and a receiver in molecular networks. It addresses key challenges in molecular communication, such as lack of synchronization and high inter-symbol interference, and scales up to four transmitters in the synthetic testbed evaluation.
                </p>
                <div class="pub-links">
                    <a href="https://dl.acm.org/doi/pdf/10.1145/3603269.3604881" class="pub-link">
                        <i class="fa-regular fa-file-lines fa-lg" style="color: #000000;"></i> Paper
                    </a>
                    <div class="separator-line"></div>
                    <a href="https://github.com/JMWinding/MoMA" class="pub-link">
                        <i class="fa-solid fa-code fa-lg" style="color: #000000;"></i> Code
                    </a>
                    <div class="separator-line"></div>
                    <a href="citations/citation-sigcomm.html" class="pub-link">
                        <i class="fa-solid fa-quote-right" style="color: #000000;"></i> Cite
                    </a>                      
                </div>
            </div>
        </div>
    
        <div class="marker" style="top: 3vw;">
            <a href="https://jmlr.org/tmlr/index.html">
            <div class="date">TMLR 2023</div>
            </a>
            <div class="pub-box">
                <strong style="font-size: 1.4em;">
                    Contextual Combinatorial Multi-output GP Bandits with Group Constraints
                </strong>
                <br><br>                
                <img src="images/tmlr.png" class="pub-img" style="max-width: 65%;">
                <p>
                    This paper proposes TCGP-UCB which is an algorithm for combinatorial contextual bandit problems with privacy-driven group constraints. It balances between maximizing cumulative super arm reward and satisfying group reward constraints and can be tuned to prefer one over the other, with information-theoretic regret bounds.
                </p>
                <div class="pub-links">
                    <a href="https://openreview.net/pdf?id=OqbGu3hdQb" class="pub-link">
                        <i class="fa-regular fa-file-lines fa-lg" style="color: #000000;"></i> Paper
                    </a>
                    <div class="separator-line"></div>
                    <a href="https://github.com/Bilkent-CYBORG/TCGP-UCB" class="pub-link">
                        <i class="fa-solid fa-code fa-lg" style="color: #000000;"></i> Code
                    </a>
                    <div class="separator-line"></div>
                    <a href="citations/citation-tmlr.html" class="pub-link">
                        <i class="fa-solid fa-quote-right" style="color: #000000;"></i> Cite
                    </a>                      
                </div>              
            </div>
        </div>
    
        <div class="marker" style="top: 3vw;">
            <a href="https://uyms21.ege.edu.tr/sempozyumProgrami.html">
            <div class="date">UYMS 2021</div>
            </a>
            <div class="pub-box">
                <strong style="font-size: 1.4em;">
                    A Performance Study Depending on Execution Times of Various Frameworks in Machine Learning Inference
                </strong>
                <br><br>
                <img src="images/uyms.png" class="pub-img" style="max-width: 60%;">
                <p>
                    This study benchmarks inference latency across multiple machine learning frameworks using a 2-layer neural network model. The model is implemented in PyTorch and converted to TorchScript and ONNX formats. Inference is performed using LibTorch, ONNX Runtime, and TensorRT on both CPU and GPU. Results show that TensorRT with ONNX delivers the fastest performance, demonstrating its efficiency and potential for deployment scenarios.
                </p>
                <div class="pub-links">
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9659677" class="pub-link">
                        <i class="fa-regular fa-file-lines fa-lg" style="color: #000000;"></i> Paper
                    </a>
                    <div class="separator-line"></div>
                    <a href="citations/citation-uyms.html" class="pub-link">
                        <i class="fa-solid fa-quote-right" style="color: #000000;"></i> Cite
                    </a>                       
                </div>              
            </div>
        </div>
    </div>
</div>

<script>
window.onload = function() {
    var topLine = document.querySelector('.top-line');
    var bottomLine = document.querySelector('.bottom-line');

    topLine.style.width = '25%';
    bottomLine.style.width = '25%';
};
</script>